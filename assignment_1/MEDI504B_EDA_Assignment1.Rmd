---
title: "MEDI 504B Assignment 1"
author: "Kira Tosesky, Irvin Ng, Johnathan Wong"
output: github_document
date: "2024-01-12"
always_allow_html: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # for tidy data analysis
library(readr)     # for fast reading of input files
library(DataExplorer) # for automated data exploration
library(ellipse)
library(ggplot2)
library(RColorBrewer)
library(gridExtra)
library(igraph)
```

```{r, echo = TRUE, eval = FALSE}
DiabetesHIDataSet_train <-
  read_csv(
    "~/DiabetesHIDataSet_train.csv",
    col_types = cols(
      AnyHealthcare = col_factor(levels = c("0", "1")),
      CholCheck = col_factor(levels = c("0", "1")),
      Diabetes_binary = col_factor(levels = c("0", "1")),
      DiffWalk = col_factor(levels = c("0", "1")),
      Fruits = col_factor(levels = c("0", "1")),
      HeartDiseaseorAttack = col_factor(levels = c("0", "1")),
      HighBP = col_factor(levels = c("0", "1")),
      HighChol = col_factor(levels = c("0", "1")),
      HvyAlcoholConsump = col_factor(levels = c("0", "1")),
      NoDocbcCost = col_factor(levels = c("0", "1")),
      PhysActivity = col_factor(levels = c("0", "1")),
      Sex = col_factor(levels = c("0", "1")),
      Smoker = col_factor(levels = c("0", "1")),
      Stroke = col_factor(levels = c("0", "1")),
      Veggies = col_factor(levels = c("0", "1"))
    )
  )
saveRDS(DiabetesHIDataSet_train, file = "DiabetesHIDataSet_train.RDS")
```


```{r}
DiabetesHIDataSet_train <-  readRDS("DiabetesHIDataSet_train.RDS")
DiabetesHIDataSet_train <- DiabetesHIDataSet_train %>%
  mutate(Diabetes_binary = recode_factor(Diabetes_binary, `0` = "No diabetes", `1` = "Diabetes"))
str(DiabetesHIDataSet_train, give.attr = FALSE)
# Exploratory Data Analysis----
summary(DiabetesHIDataSet_train)  # Basic 
```
> Our dataset contains 49,564 and 22 features. Of the 22 features, 15 are categorical, all of which are binary. The remaining 7 features are binary.

```{r}
# Define the ranges for each of the integer variables
income_categories <- range(DiabetesHIDataSet_train$Income)
genhlth_categories <- range(DiabetesHIDataSet_train$GenHlth)
menthlth_categories <- range(DiabetesHIDataSet_train$MentHlth)
physlth_categories <- range(DiabetesHIDataSet_train$PhysHlth)
age_categories <- range(DiabetesHIDataSet_train$Age)
education_categories <- range(DiabetesHIDataSet_train$Education)
bmi_possible_values <- range(DiabetesHIDataSet_train$BMI)

# Number of binary variables
num_binary_variables <- DiabetesHIDataSet_train %>%
  select_if(is.factor) %>%
  ncol()

# Calculate the probability for binary variables
prob_binary <- (1 / 2) ^ num_binary_variables

# Calculate the probability for integer variables
prob_integer <-
  (1 / income_categories) * (1 / genhlth_categories) * (1 / menthlth_categories) *
  (1 / physlth_categories) * (1 / age_categories) * (1 / education_categories) *
  (1 / bmi_possible_values)

# Final probability of two individuals having identical records
probability_identical <- prob_binary * prob_integer
probability_identical

num_records <- nrow(DiabetesHIDataSet_train)
#calculate probability of any instance of a "real" duplicate in dataset (i.e. two unique individuals with matching values across all columns)
probability_identical * num_records
```
> Based on these probablities, it is unlikely that any identical records are from unique individuals, so we can remove duplicates safely.

```{r}
# Does each row repesent a unique patient record?
# Find duplicated rows based on all columns
duplicated_rows <-
  DiabetesHIDataSet_train[duplicated(DiabetesHIDataSet_train), ]

# View the duplicated rows
print(duplicated_rows)

# Calculate number of duplicated rows
print(nrow(duplicated_rows))

# Keep only unique rows in the dataframe
DiabetesHIDataSet_train_unique <- unique(DiabetesHIDataSet_train)
```
> There are 905 duplicated rows in our dataset.

```{r, eval=FALSE}
# Automated EDA
create_report(DiabetesHIDataSet_train_unique, output_format = "pdf_document", output_file = "report.pdf")
```


> Based on the automated EDA, our dataset is not missing any observations. This is consistent with the metadata. The description of *MentlHlth* and *PhysHlth* in the metadata, however, did not match what we see in the histogram analysis. These two columns indicate the number of days the patient did not feel mentally or physically well in the last 30 days using a scale of 1-30. The data, however, shows that 0 is a possible value. Given that it is possible to not feel unwell in the last 30 days, we are inclined to believe the metadata is incorrect.

> Based on the histograms generated, we also found some outliers in the `BMI` features. There are some observations in the 60+ range with a max BMI of 98. We believe these outliers are biological, thus we do not remove them.

> In the correlation analysis, we see that *MentlHlth*, *PhysHlth*, *GenHlth* and *BMI* are clustered and positively correlated with each other. This is expected as these features can influence one and another, according to literature (need to find a citation). Furthermore, we observe a positive correlation between the features `DiffWalk` and `Diabetes_binary` and these features, indicating that difficulty in walking and having diabetes are correlated with these factors.

> Finally in the principal component analysis, we see that PC1 only accounted for 15.9% of the variance, showing that no single principal component explained a high variance in the data.

```{r}
diabetes_pred <-
  DiabetesHIDataSet_train_unique %>% select(-Diabetes_binary)
  diabetes_class <- DiabetesHIDataSet_train_unique$Diabetes_binary
  
  
  # Exploratory Data Analysis
  ggplot(DiabetesHIDataSet_train_unique,
  aes(x = Diabetes_binary, fill = Diabetes_binary)) + geom_bar() + theme_bw()
```

> Our dataset is fairly balanced.

```{r}
# Define a smaller size for the mean points
mean_point_size <- 3

# Define color palette
colors <-
  brewer.pal(length(unique(stack(diabetes_pred)$ind)), "Set3")

int_feat_violin_plot <-
  ggplot(stack(diabetes_pred), aes(x = ind, y = values, fill = ind)) +
  geom_violin() +
  ylab("Values") +
  xlab("Integer Features") +
  labs(fill = "Integer Features") +
  stat_summary(fun = mean, geom = "point") +
  theme_bw()

# Display the plot
int_feat_violin_plot

```


```{r eval=FALSE}
# Select only integer columns, excluding 'Diabetes_binary' for reshaping
integer_cols <- sapply(DiabetesHIDataSet_train_unique, is.integer) & names(DiabetesHIDataSet_train_unique) != "Diabetes_binary"

#DiabetesHIDataSet_train_unique %>%
#  select(which(integer_cols), Diabetes_binary) %>%
#  pivot_longer(cols = -Diabetes_binary, names_to = "variable", values_to = "value") %>%
#  ggplot(aes(x = value, fill = Diabetes_binary, color = Diabetes_binary)) +
#  geom_density(alpha = 0.3) +
#  facet_wrap(~ variable, scales = "free") +
#  theme_bw()


# Assuming 'diabetes_data2' is your dataframe

# Identify integer columns, excluding 'Diabetes_binary'
integer_cols <- sapply(DiabetesHIDataSet_train_unique, is.integer) & names(DiabetesHIDataSet_train_unique) != "Diabetes_binary"

# Reshape the data
long_data <- DiabetesHIDataSet_train_unique %>%
  select(which(integer_cols), Diabetes_binary) %>%
  pivot_longer(cols = -Diabetes_binary, names_to = "variable", values_to = "value")

# Subset for BMI (if BMI is an integer and part of the data)
bmi_data <- long_data %>% filter(variable == "BMI")

# Subset for other variables
other_data <- long_data %>% filter(variable != "BMI")

# Create density plot for BMI
density_plot <- ggplot(bmi_data, aes(x = value, fill = Diabetes_binary, color = Diabetes_binary)) +
  geom_density(alpha = 0.3) +
  labs(x = "BMI", y = "Density") +
  theme_minimal()

# Create bar plots for other variables
bar_plots <- ggplot(other_data, aes(x = value, fill = Diabetes_binary)) +
  geom_bar(position = "stack") +
  facet_wrap(~ variable, scales = "free") +
  labs( x = "Value", y = "Count") +
  theme_minimal()

# Arrange the plots
grid.arrange(density_plot, bar_plots, ncol = 1)

```
```{r, eval=FALSE}
gather(DiabetesHIDataSet_train_unique, x, y, DiabetesHIDataSet_train_unique:Income) %>%  # selecting data pairs
  ggplot(aes(x = y, color = Diabetes_binary, fill = Diabetes_binary)) +
  geom_density(alpha = 0.3) +
  facet_wrap( ~ x, scales = "free", ncol = 3)
```


```{r, fig.width=24, fig.height=12}
# Create correlation matrices
# Benign
co_mat_nodiabetes <-
  filter(DiabetesHIDataSet_train_unique,
         Diabetes_binary == "No diabetes") %>%
  select(-Diabetes_binary) %>%
  sapply(function(x)
    as.numeric(as.character(x))) %>%
  cor()
# Malignant
co_mat_diabetes <-
  filter(DiabetesHIDataSet_train_unique, Diabetes_binary == "Diabetes") %>%
  select(-Diabetes_binary) %>%
  sapply(function(x)
    as.numeric(as.character(x))) %>%
  cor()


g_nodiabetes <-
  graph.adjacency(
    co_mat_nodiabetes,
    weighted = TRUE,
    mode = "upper",
    diag = FALSE
  )
g_diabetes <-
  graph.adjacency(co_mat_diabetes,
                  weighted = TRUE,
                  mode = "upper",
                  diag = FALSE)

cut.off_nd <- mean(E(g_nodiabetes)$weight, na.rm = TRUE)
cut.off_d <- mean(E(g_diabetes)$weight)


g_nodiabetes_2 <-
  delete_edges(g_nodiabetes, which(E(g_nodiabetes)$weight < cut.off_nd))
g_diabetes_2 <-
  delete_edges(g_diabetes, which(E(g_diabetes)$weight < cut.off_d))


c_g_nodiabetes_2 <-
  cluster_fast_greedy(g_nodiabetes_2) # implements network clustering methods
c_g_diabetes_2 <- cluster_fast_greedy(g_diabetes_2)

par(mar = c(5, 5, 2, 2), cex.main = 2)
plot(
  c_g_nodiabetes_2,
  g_nodiabetes_2,
  vertex.size = colSums(co_mat_nodiabetes) * 10,
  # the larger the vertex/node the more correlated that vertex is with other features
  vertex.frame.color = NA,
  vertex.label.color = "black",
  vertex.label.cex = 1.5,
  edge.width = E(g_nodiabetes_2)$weight * 15,
  layout = layout_with_fr(g_nodiabetes_2),
  main = "No diabetes"
)
```

```{r, fig.width=24, fig.height=12}
par(cex.main = 2)
plot(
  c_g_diabetes_2,
  g_diabetes_2,
  vertex.size = colSums(co_mat_diabetes) * 10,
  # the larger the vertex/node the more correlated that vertex is with other features
  vertex.frame.color = NA,
  vertex.label.color = "black",
  vertex.label.cex = 1.5,
  edge.width = E(g_diabetes_2)$weight * 15,
  layout = layout_with_fr(g_diabetes_2),
  main = "Diabetes"
)
```

> For both groups, the features were clustered into three groups. We can also see that the clusters were fairly similar to each other. The width of the edges in these plots indicate the weight which correspond to the strength of the correlation between the nodes. We observe that life style choices like eating vegetables and fruits correlate strongly with each other. Education and income also correlate strongly with each other. The size of each node is based on the sum of the correlation of that feature and we observe that features directly related to health have the highest sum.

```{r}
# Principal Component Analysis

DiabetesHIDataSet_train_unique_num <-
  sapply(DiabetesHIDataSet_train_unique, as.numeric) %>% as.data.frame()
# perform pca and extract scores
pcaOutput <-
  prcomp(as.matrix(
    select(DiabetesHIDataSet_train_unique_num,-Diabetes_binary)
  ), scale = TRUE, center = TRUE)
pcaOutput2 <- as.data.frame(pcaOutput$x)
PoV <- pcaOutput$sdev ^ 2 / sum(pcaOutput$sdev ^ 2)
PoV
```

> Here we can once again see that no PCA component explained more 16.9% of the variance in the data.

```{r}
# define groups for plotting
pcaOutput2$groups <-
  as.factor(DiabetesHIDataSet_train_unique_num$Diabetes_binary)

centroids <- aggregate(cbind(PC1, PC2) ~ groups, pcaOutput2, mean)

conf.rgn  <-
  do.call(rbind, lapply(unique(pcaOutput2$groups), function(t)
    data.frame(
      groups = as.character(t),
      ellipse(
        cov(pcaOutput2[pcaOutput2$groups == t, 1:2]),
        centre = as.matrix(centroids[centroids$groups == t, 2:3]),
        level = 0.95
      ),
      stringsAsFactors = FALSE
    )))


pca_plot <-
  ggplot(data = pcaOutput2, aes(
    x = PC1,
    y = PC2,
    group = groups,
    color = groups
  )) +
  geom_polygon(data = conf.rgn, aes(fill = groups), alpha = 0.2) +
  geom_point(size = 2, alpha = 0.6) +
  labs(color = "", fill = "") +
  labs(
    x = paste0("PC1: ", round(PoV[1], digits = 2) * 100, "% variance"),
    y = paste0("PC2: ", round(PoV[2], digits = 2) * 100, "% variance")
  )

pca_plot
```

> The low variance explained by the principal components suggests that these components are not capturing a significant amount of information about the differences in the data. This is recapitulated in the scatterplot where there are larger overlap of data points and no distinct patterns.

```{r}
# Basic summary stats
psych::describeBy(DiabetesHIDataSet_train_unique_num)
psych::describeBy(diabetes_pred, diabetes_class)
```

> Separating the data by groups reveals a clear distinction in mean and median values.

```{r}
# a better looking table
arsenal::tableby(Diabetes_binary ~ ., data = DiabetesHIDataSet_train_unique, total = TRUE) %>% summary(text = TRUE)
```

> Every feature demonstrates statistical significance in explaining the model. This observation aligns with the distribution of features after being separated by class.